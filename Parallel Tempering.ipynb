{
 "metadata": {
  "name": ""
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Parallel tempering"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Training Restricted Boltzmann Machines: An Introductio by Fischer <br>\n",
      "Improved Learning Algorithms for Restricted Boltzmann Machines by Cho <br>\n",
      "\n",
      "\n",
      "Parallel tempering (PT) is designed to overcome the limitations of Metropolis-Hasting algorithms (like Gibbs sampling) when sampling from multi-modal target distributions and as a result to lead to faster mixing Markov chains (Swendsen and Wang, 1986;\n",
      "Geyer, 1991). Consistently, empirical studies show that using PT for RBM training results in better generative models and can prevent the likelihood from diverging (Desjardins et al., 2010b; Cho et al., 2010). Parallel tempering introduces supplementary Gibbs chains that sample from smoothed replicas of the original distribution\u2014with the goal of improving the mixing rate.\n",
      "\n",
      "Consider a multi modal target density \u21e1 on a state space \u2326 from which one would like to sample via a Markov chain. The transition steps of the Metropolis-Hastings algorithm move only locally in space so that the resulting Markov chain may move between the modes of \u21e1 only infrequently. The PT algorithm [8] tries to overcome this by introducing supplementary Markov\n",
      "chains, which are \u201cflattened\u201d or \u201csmoothed\u201d versions of \u21e1. These (and the original density) are referred to as tempered densities \u21e1t, t = 0, . . . ,N fulfilling \u21e1t(z) / \u21e1(z)\"t for z 2 \u2326 with inverse temperatures $t.\n",
      "\n",
      "The inverse temperatures satisfy 0 \uf8ff $0 < \u00b7 \u00b7 \u00b7 < $N = 1. Parallel tempering now constructs a Markov chain on the joint state space \u2326PT = \u2326N+1 of the tempered distributions. The chain takes values x = (x[0], . . . , x[N]) 2 \u2326PT and converges\n",
      "to the stationary distribution <br>\n",
      "\n",
      "\n",
      "$$a(x,t) = min {1, \\frac{\\pi (x_{t+1} \\pi (x_t))}{\\pi (x_t) \\pi (x_{t+1})}}$$\n",
      "\n",
      "<br>\n",
      "<br>\n",
      "<br>\n",
      "Consider the target distribution from which we wish to draw samples, given by:\n",
      "\n",
      "$$p(x) = \\frac{1}{Z(\\theta)} exp(-E(x))$$\n",
      "\n",
      "We create an extended system by augmenting the target distribution with an indexed temperature parameter <br>\n",
      "\n",
      "At high temperatures (ti>>1), the effect of the temperature parameter is to smooth the distribution, as the effective energies become more uniform (uniformlyzero) over the sampling space. In the case of Parallel tempering, the strategy is to simulate from multiple MCMC chains, each at one of an ordered sequence of temperatures ti from temperature t0 = 1 that samples from the distribution of interest (the target distribution) to a high temperature tT=\u03c4,i.e\n",
      "\n",
      "At high temperatures, the chain mixes well but is not sampling from the distribution in which we are interested, so the following question remains: how do we make use of the well mixing chains running at high temperatures to improve sampling efficiency from ou target distribution at t0= 1?  In parallel tempering this question is addressed via the introduction of\n",
      "cross temperature state swaps. At each time-step, two neighbouring chains running at temperature tk and tk+1 may exchange their particles xk and xk+1 with an exchange probability given by: <br>\n",
      "\n",
      "\n",
      "\n",
      "A  problem  that  has  not  been  addressed  neither  by  Gibbs sampling nor  by  CD  learning is  that the  samples  generated\n",
      "during the  negative phase  do not tend  to  explain the  whole state space. This paper, therefore, proposes to use yet another, improved  variant  of  Markov-Chain  Monte  Carlo  sampling method called parallel tempering (PT) [9]. PT sampling used in  this  paper  utilizes  multiple  Gibbs  sampling  chains  with varying  levels  of  temperatures,  where  a  term\n",
      "temperature denotes the level of the energy of the overall system, in this case,  RBM.  The  higher  the  temperature  of  the  chain,  the more likely the samples collected by Gibbs sampling to move freely. The use of PT sampling in training RBM is simply to use it instead of Gibbs sampling in the negative phase. Due to the previously mentioned characteristics,  it  is  expected that the samples  collected  during  the  negative  phase  would  explain the  model  distribution  better,  and  that  the  learning  proces s would be done well even with a smaller number of samples than those required if Gibbs sampling is used The basic idea of PT sampling is that samples are collected from multiple chains of Gibbs sampling with different tem-\n",
      "peratures from the highest temperature T = 0 to the current temperature T = 11. For every pair of collected samples from\n",
      "two distinct chains, the swap probability is computed, and the samples are swapped according to the probability. The swap\n",
      "probability of  a  pair  of  samples  is  formulated according to the Metropolis rule (see e.g. [4]) as"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}