{
 "metadata": {
  "name": "",
  "signature": "sha256:b2d0c06f50b630afcdd8f76720d42c4d51441385cf215e5df6cba4d8afc8d8be"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "## Training an MLP\n",
      "\n",
      "To train an MLP, we learn **all** parameters of the model ($W, \\mathbf{b}, V,\n",
      "\\mathbf{c}$) by gradient descent,\n",
      "just as we learned the parameters $W, \\mathbf{b}$ previously when training the\n",
      "SVM.\n",
      "\n",
      "\n",
      "The initial values for the weights of a hidden layer ($V$) should be uniformly\n",
      "sampled from a symmetric interval that depends on the activation function.\n",
      "For the tanh activation function results obtained in [Xavier10]_ show that the\n",
      "interval should be\n",
      "$$\n",
      "\\left[ -\\sqrt{\\frac{6}{D_0 + D_1}}, \\sqrt{\\frac{6}{D_0 + D_1}} \\right]\n",
      "$$\n",
      "\n",
      "For the logistic sigmoid function $1 / (1 + e^{-u})$ the interval is slightly\n",
      "different:\n",
      "\n",
      "$$\n",
      "\\left[ -4\\sqrt{\\frac{6}{D_0 + D_1}},4\\sqrt{\\frac{6}{D_0 + D_1}} \\right]\n",
      "$$.\n",
      "\n",
      "This initialization ensures that at least early in training, each neuron operates in a regime of its activation function where information can easily be propagated both upward (activations flowing from inputs to outputs) and backward (gradients flowing from outputs to inputs)."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "### Tips and Tricks: Learning Rate\n",
      "\n",
      "Optimization by stochastic gradient descent is very sensitive to the step size or _learning rate_.\n",
      "There is a great deal of literature on how to choose a the learning rate, and how to change it during optimization.\n",
      "The simplest solution is to use a constant rate. Rule of thumb: try\n",
      "several log-spaced values ($10^{-1}, 10^{-2}, \\ldots$) and narrow the\n",
      "(logarithmic) grid search to the region where you obtain the lowest\n",
      "validation error.\n",
      "\n",
      "Decreasing the learning rate over time can help a model to settle down into a\n",
      "[local] minimum.\n",
      "One simple rule for doing that is $\\frac{\\mu_0}{1 + d\\times t}$ where\n",
      "$\\mu_0$ is the initial rate (chosen, perhaps, using the grid search\n",
      "technique explained above), $d$ is a so-called \"decrease constant\"\n",
      "which controls the rate at which the learning rate decreases (typically, a\n",
      "smaller positive number, $10^{-3}$ and smaller) and $t$ is the epoch/stage.\n",
      "\n",
      "[Section 4.7](http://yann.lecun.com/exdb/publis/pdf/lecun-98b.pdf) details\n",
      "procedures for choosing a learning rate for each parameter (weight) in our\n",
      "network and for choosing them adaptively based on the error of the classifier.\n",
      "\n",
      "### Tips and Tricks: Norm Regularization\n",
      "\n",
      "Typical values to try for the L1/L2 regularization parameter $\\lambda$ are $10^{-2}, 10^{-3}, \\ldots$.\n",
      "It can be useful to regularize the topmost layers in an MLP (closest\n",
      "to and including the classifier itself) to prevent them from overfitting noisy\n",
      "hidden layer features, and to encourage the features themselves to be more\n",
      "discriminative."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}